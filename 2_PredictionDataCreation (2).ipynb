{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07f2263-4935-46bc-8a20-008feae09b88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " #%conda env update -f env.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fbd4d3",
   "metadata": {},
   "source": [
    "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/SatelliteVu/SatelliteVu-AWS-Disaster-Response-Hackathon/blob/main/dataset_preparation/2_PredictionDataCreation.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19810f47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from pathlib import Path\n",
    "from random import sample\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import s3fs\n",
    "from shapely.geometry import box\n",
    "import rasterio\n",
    "from rasterio.errors import RasterioIOError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8be4d251-8895-4012-8bde-85f1a1e323b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.constants import FIRMS_API_KEY, DEFAULT_PARAMS\n",
    "from src.data_sources import (cluster_fires, \n",
    "                              create_chip_bounds, \n",
    "                              ndvi_from_topleft, \n",
    "                              landcover_from_topleft, \n",
    "                              atmospheric_from_topleft, \n",
    "                              fires_from_topleft,\n",
    "                              elevation_from_topleft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023bd837-eabb-4a92-b5fe-a891d72abb58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "if not FIRMS_API_KEY:\n",
    "    raise ValueError('FIRMS_API_KEY empty, please ensure your environment variable set')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4968d377-2745-4d42-86fc-9507f29184f7",
   "metadata": {},
   "source": [
    "# Input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca7162f8-eb69-44ef-9a4a-19b535ede650",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_fp = '/home/studio-lab-user/sagemaker-studiolab-notebooks/hackathon_data/predict_test'\n",
    "# os.environ['AWS_S3_BUCKET'] = 's3://wildfireneu'\n",
    "# output_s3 = os.environ['AWS_S3_BUCKET'] + '/predict_test_2'\n",
    "\n",
    "# North America\n",
    "bbox= [-168.7,24.8,-51.8,74.2]\n",
    "\n",
    "# dates to search for fires\n",
    "begin_date = datetime(2021,12,1)\n",
    "end_date   = datetime(2021,12,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aefeaad-bba9-4d5e-812f-37e2822ed893",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fs = s3fs.S3FileSystem(key=os.environ['AWS_ACCESS_KEY_ID'], secret=os.environ['AWS_SECRET_ACCESS_KEY'])\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1aa52a-ff28-449a-9d14-de42a8ddf6b4",
   "metadata": {},
   "source": [
    "# Load fire data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a44b6dc8-243c-4cfa-9cda-d191e65376d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_fires(begin_date, end_date, bbox, day_range=10):\n",
    "    \"\"\"\n",
    "    Given input parameters, search NASA firms API for fires and return GeoDataFrame of fire points\n",
    "    :param begin_date: datetime\n",
    "    :param end_date: datetime\n",
    "    :param bbox: list of floats; left, bottom, right, top\n",
    "    :param day_range: int for the number of days to search API for\n",
    "    :return: gpd.GeoDataFrame of fire points\n",
    "    \"\"\"\n",
    "    if day_range > 10:\n",
    "        # firms api allows max of 10 day range see https://firms.modaps.eosdis.nasa.gov/api/area/\n",
    "        raise ValueError('\"day_range\" must be less than or equal to 10')\n",
    "\n",
    "    start_dates = (pd.date_range(start=begin_date, end=end_date, freq=f\"{day_range}D\") + pd.Timedelta(f'{day_range}d')).to_pydatetime().tolist()\n",
    "    if len(start_dates) == 0:\n",
    "        raise ValueError('No dates to search for, check \"begin_date\" and \"end_date\" are formated correctly')\n",
    "        \n",
    "    # get min date of the VIIRS_SNPP_NRT so that we can decide based on the date range which FIRMS product(s) we need\n",
    "    viirs_nrt = pd.read_csv(f'https://firms.modaps.eosdis.nasa.gov/api/data_availability/csv/{FIRMS_API_KEY}/VIIRS_SNPP_NRT')\n",
    "    viirs_nrt_start = datetime.strptime(viirs_nrt.iloc[0].min_date, '%Y-%m-%d')\n",
    "\n",
    "    df_fires = pd.DataFrame()\n",
    "    for start_date in start_dates:\n",
    "        mapkey_status = requests.get(f'https://firms.modaps.eosdis.nasa.gov/mapserver/mapkey_status/?MAP_KEY={FIRMS_API_KEY}')\n",
    "        if mapkey_status.json()['current_transactions'] > 460:\n",
    "            # TODO: tenacity retry wait_exponential:\n",
    "            raise ValueError('Not enough free transactions left with FIRMS API for given key')\n",
    "\n",
    "        # split requests by date for VIIRS_SNPP_SP/VIIRS_SNPP_NRT\n",
    "        if start_date > viirs_nrt_start:\n",
    "            nrt_request_url = f'https://firms.modaps.eosdis.nasa.gov/api/area/csv/{FIRMS_API_KEY}/VIIRS_SNPP_NRT/{\",\".join([str(i) for i in bbox])}/{day_range}/{start_date.strftime(\"%Y-%m-%d\")}'\n",
    "            df_fires=df_fires.append(pd.read_csv(nrt_request_url),ignore_index=True)\n",
    "        if (start_date - timedelta(days=day_range)) < viirs_nrt_start:\n",
    "            sp_request_url = f'https://firms.modaps.eosdis.nasa.gov/api/area/csv/{FIRMS_API_KEY}/VIIRS_SNPP_SP/{\",\".join([str(i) for i in bbox])}/{day_range}/{start_date.strftime(\"%Y-%m-%d\")}'\n",
    "            df_fires=df_fires.append(pd.read_csv(sp_request_url),ignore_index=True)\n",
    "\n",
    "    # drop fires after end_date\n",
    "    df_fires = df_fires[((df_fires['acq_date'].astype('datetime64[ns]') <= end_date) & (df_fires['acq_date'].astype('datetime64[ns]') >= begin_date))]\n",
    "    gdf_fires = gpd.GeoDataFrame(df_fires, geometry=gpd.points_from_xy(df_fires.longitude, df_fires.latitude), crs='EPSG:4326')\n",
    "    return gdf_fires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c7d242a-3dfd-4ad1-b07c-9399e8390e79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): firms.modaps.eosdis.nasa.gov:443\n",
      "DEBUG:urllib3.connectionpool:https://firms.modaps.eosdis.nasa.gov:443 \"GET /mapserver/mapkey_status/?MAP_KEY=8b3579dbaf217e12dc49960662286f22 HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): firms.modaps.eosdis.nasa.gov:443\n",
      "DEBUG:urllib3.connectionpool:https://firms.modaps.eosdis.nasa.gov:443 \"GET /mapserver/mapkey_status/?MAP_KEY=8b3579dbaf217e12dc49960662286f22 HTTP/1.1\" 200 None\n",
      "DEBUG:pyproj:PROJ_ERROR: proj_create: unrecognized format / unknown name\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>bright_ti4</th>\n",
       "      <th>scan</th>\n",
       "      <th>track</th>\n",
       "      <th>acq_date</th>\n",
       "      <th>acq_time</th>\n",
       "      <th>satellite</th>\n",
       "      <th>instrument</th>\n",
       "      <th>confidence</th>\n",
       "      <th>version</th>\n",
       "      <th>bright_ti5</th>\n",
       "      <th>frp</th>\n",
       "      <th>daynight</th>\n",
       "      <th>type</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.61243</td>\n",
       "      <td>-87.32779</td>\n",
       "      <td>318.28</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2021-12-11</td>\n",
       "      <td>717</td>\n",
       "      <td>N</td>\n",
       "      <td>VIIRS</td>\n",
       "      <td>n</td>\n",
       "      <td>2</td>\n",
       "      <td>284.21</td>\n",
       "      <td>2.49</td>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "      <td>POINT (-87.32779 41.61243)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.61656</td>\n",
       "      <td>-87.32710</td>\n",
       "      <td>305.80</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2021-12-11</td>\n",
       "      <td>717</td>\n",
       "      <td>N</td>\n",
       "      <td>VIIRS</td>\n",
       "      <td>n</td>\n",
       "      <td>2</td>\n",
       "      <td>283.73</td>\n",
       "      <td>1.58</td>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "      <td>POINT (-87.32710 41.61656)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.61703</td>\n",
       "      <td>-87.33204</td>\n",
       "      <td>316.36</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2021-12-11</td>\n",
       "      <td>717</td>\n",
       "      <td>N</td>\n",
       "      <td>VIIRS</td>\n",
       "      <td>n</td>\n",
       "      <td>2</td>\n",
       "      <td>283.63</td>\n",
       "      <td>1.58</td>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "      <td>POINT (-87.33204 41.61703)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.62444</td>\n",
       "      <td>-87.14648</td>\n",
       "      <td>300.47</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.44</td>\n",
       "      <td>2021-12-11</td>\n",
       "      <td>717</td>\n",
       "      <td>N</td>\n",
       "      <td>VIIRS</td>\n",
       "      <td>n</td>\n",
       "      <td>2</td>\n",
       "      <td>283.55</td>\n",
       "      <td>0.73</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (-87.14648 41.62444)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.62857</td>\n",
       "      <td>-87.36546</td>\n",
       "      <td>313.27</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2021-12-11</td>\n",
       "      <td>717</td>\n",
       "      <td>N</td>\n",
       "      <td>VIIRS</td>\n",
       "      <td>n</td>\n",
       "      <td>2</td>\n",
       "      <td>281.88</td>\n",
       "      <td>1.46</td>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "      <td>POINT (-87.36546 41.62857)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3459</th>\n",
       "      <td>45.57653</td>\n",
       "      <td>-118.59241</td>\n",
       "      <td>331.43</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2021-12-15</td>\n",
       "      <td>2049</td>\n",
       "      <td>N</td>\n",
       "      <td>VIIRS</td>\n",
       "      <td>n</td>\n",
       "      <td>2</td>\n",
       "      <td>274.07</td>\n",
       "      <td>12.20</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (-118.59241 45.57653)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3460</th>\n",
       "      <td>45.57795</td>\n",
       "      <td>-118.58245</td>\n",
       "      <td>327.51</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2021-12-15</td>\n",
       "      <td>2049</td>\n",
       "      <td>N</td>\n",
       "      <td>VIIRS</td>\n",
       "      <td>n</td>\n",
       "      <td>2</td>\n",
       "      <td>274.66</td>\n",
       "      <td>15.83</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (-118.58245 45.57795)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3461</th>\n",
       "      <td>46.07195</td>\n",
       "      <td>-118.89924</td>\n",
       "      <td>327.61</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2021-12-15</td>\n",
       "      <td>2049</td>\n",
       "      <td>N</td>\n",
       "      <td>VIIRS</td>\n",
       "      <td>n</td>\n",
       "      <td>2</td>\n",
       "      <td>280.98</td>\n",
       "      <td>2.89</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (-118.89924 46.07195)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3462</th>\n",
       "      <td>46.07525</td>\n",
       "      <td>-118.90021</td>\n",
       "      <td>328.44</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2021-12-15</td>\n",
       "      <td>2049</td>\n",
       "      <td>N</td>\n",
       "      <td>VIIRS</td>\n",
       "      <td>n</td>\n",
       "      <td>2</td>\n",
       "      <td>280.82</td>\n",
       "      <td>2.89</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (-118.90021 46.07525)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3463</th>\n",
       "      <td>46.11163</td>\n",
       "      <td>-118.99693</td>\n",
       "      <td>334.98</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2021-12-15</td>\n",
       "      <td>2049</td>\n",
       "      <td>N</td>\n",
       "      <td>VIIRS</td>\n",
       "      <td>n</td>\n",
       "      <td>2</td>\n",
       "      <td>278.03</td>\n",
       "      <td>3.00</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (-118.99693 46.11163)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3464 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      latitude  longitude  bright_ti4  scan  track    acq_date  acq_time  \\\n",
       "0     41.61243  -87.32779      318.28  0.41   0.45  2021-12-11       717   \n",
       "1     41.61656  -87.32710      305.80  0.41   0.45  2021-12-11       717   \n",
       "2     41.61703  -87.33204      316.36  0.41   0.45  2021-12-11       717   \n",
       "3     41.62444  -87.14648      300.47  0.40   0.44  2021-12-11       717   \n",
       "4     41.62857  -87.36546      313.27  0.41   0.45  2021-12-11       717   \n",
       "...        ...        ...         ...   ...    ...         ...       ...   \n",
       "3459  45.57653 -118.59241      331.43  0.39   0.36  2021-12-15      2049   \n",
       "3460  45.57795 -118.58245      327.51  0.39   0.36  2021-12-15      2049   \n",
       "3461  46.07195 -118.89924      327.61  0.39   0.36  2021-12-15      2049   \n",
       "3462  46.07525 -118.90021      328.44  0.39   0.36  2021-12-15      2049   \n",
       "3463  46.11163 -118.99693      334.98  0.39   0.36  2021-12-15      2049   \n",
       "\n",
       "     satellite instrument confidence  version  bright_ti5    frp daynight  \\\n",
       "0            N      VIIRS          n        2      284.21   2.49        N   \n",
       "1            N      VIIRS          n        2      283.73   1.58        N   \n",
       "2            N      VIIRS          n        2      283.63   1.58        N   \n",
       "3            N      VIIRS          n        2      283.55   0.73        N   \n",
       "4            N      VIIRS          n        2      281.88   1.46        N   \n",
       "...        ...        ...        ...      ...         ...    ...      ...   \n",
       "3459         N      VIIRS          n        2      274.07  12.20        D   \n",
       "3460         N      VIIRS          n        2      274.66  15.83        D   \n",
       "3461         N      VIIRS          n        2      280.98   2.89        D   \n",
       "3462         N      VIIRS          n        2      280.82   2.89        D   \n",
       "3463         N      VIIRS          n        2      278.03   3.00        D   \n",
       "\n",
       "      type                     geometry  \n",
       "0        3   POINT (-87.32779 41.61243)  \n",
       "1        3   POINT (-87.32710 41.61656)  \n",
       "2        3   POINT (-87.33204 41.61703)  \n",
       "3        0   POINT (-87.14648 41.62444)  \n",
       "4        3   POINT (-87.36546 41.62857)  \n",
       "...    ...                          ...  \n",
       "3459     0  POINT (-118.59241 45.57653)  \n",
       "3460     0  POINT (-118.58245 45.57795)  \n",
       "3461     0  POINT (-118.89924 46.07195)  \n",
       "3462     0  POINT (-118.90021 46.07525)  \n",
       "3463     0  POINT (-118.99693 46.11163)  \n",
       "\n",
       "[3464 rows x 16 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_fires = load_fires(begin_date, end_date, bbox)\n",
    "gdf_fires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9c1dd73-0e3c-45b1-8592-e07d45ed5d52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering fires\n",
      "Creating chip bounds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>left</th>\n",
       "      <th>bottom</th>\n",
       "      <th>right</th>\n",
       "      <th>top</th>\n",
       "      <th>epsg</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>274125.0</td>\n",
       "      <td>3922875.0</td>\n",
       "      <td>306000.0</td>\n",
       "      <td>3954750.0</td>\n",
       "      <td>32614</td>\n",
       "      <td>2021-12-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>738000.0</td>\n",
       "      <td>3933375.0</td>\n",
       "      <td>769875.0</td>\n",
       "      <td>3965250.0</td>\n",
       "      <td>32613</td>\n",
       "      <td>2021-12-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>247500.0</td>\n",
       "      <td>4047750.0</td>\n",
       "      <td>279375.0</td>\n",
       "      <td>4079625.0</td>\n",
       "      <td>32614</td>\n",
       "      <td>2021-12-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>546750.0</td>\n",
       "      <td>4059750.0</td>\n",
       "      <td>578625.0</td>\n",
       "      <td>4091625.0</td>\n",
       "      <td>32614</td>\n",
       "      <td>2021-12-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx      left     bottom     right        top   epsg        date\n",
       "0    0  274125.0  3922875.0  306000.0  3954750.0  32614  2021-12-15\n",
       "1    1  738000.0  3933375.0  769875.0  3965250.0  32613  2021-12-15\n",
       "2    2  247500.0  4047750.0  279375.0  4079625.0  32614  2021-12-15\n",
       "3    3  546750.0  4059750.0  578625.0  4091625.0  32614  2021-12-15"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create clusters\n",
    "print('Clustering fires')\n",
    "df_fire_clustered = cluster_fires(gdf_fires)\n",
    "\n",
    "# create chip bounds\n",
    "print('Creating chip bounds')\n",
    "Path(output_fp).mkdir(parents=True, exist_ok=True)\n",
    "manifest = create_chip_bounds(df_fire_clustered)\n",
    "manifest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77965ab6-1d44-4c8f-8b54-432043649230",
   "metadata": {},
   "source": [
    "# Process Chips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d24f7c-0d49-4f40-bdc0-bbb77496e81c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_chip(chip, fs, output_fp, output_s3, fires,  training=True):\n",
    "    \"\"\"\n",
    "    Given a chips metadata, load all of the training data and write numpy files, finally upload results to S3\n",
    "    :param chip: records.csv chip to process data for\n",
    "    :param fs: s3fs.S3FileSystem\n",
    "    :param output_fp: local directory to write data to\n",
    "    :param output_s3: local directory to write data to\n",
    "    :param fires: gpd.GeoDataFrame or path to vector file containing fire point data\n",
    "    :param cog_footprints: gpd.GeoDataFrame of the dem footprints\n",
    "    :param training: bool, if true then will load/write next days fires\n",
    "    \"\"\"\n",
    "    print(\"start processing\")\n",
    "    \n",
    "    chip_idx, left, bottom, top, right, epsg, chip_date = chip[\"idx\"], chip[\"left\"], chip[\"bottom\"], chip[\"top\"], chip[\"right\"], chip[\"epsg\"], chip[\"date\"]\n",
    "    print(\"chip read completed\")\n",
    "#     if os.path.exists(output_fp + f'/{chip_idx}'):\n",
    "#         return\n",
    "    \n",
    "#     # check not already on s3\n",
    "#     if len(fs.ls(f'{output_s3}/{chip_idx}')) != 0:\n",
    "#         return\n",
    "    \n",
    "    print(f'Processing chip: {chip_idx}')\n",
    "    \n",
    "    # create output dir if it doesnt already exist\n",
    "    output_dir = Path(output_fp).joinpath(str(chip_idx))\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # # load modis\n",
    "    # try:\n",
    "    #     ndvi = ndvi_from_topleft([top, left], epsg, chip_date)\n",
    "    #     np.save(output_dir.joinpath('ndvi.npy'), ndvi)\n",
    "    #     print(\"ndvi completed\")\n",
    "    # except RasterioIOError:\n",
    "    #     # modis missing from bucket\n",
    "    #     shutil.rmtree(output_dir)\n",
    "    #     print(\"failed to load ndvi\")\n",
    "    \n",
    "    \n",
    "    # Fetch NDVI data\n",
    "    try:\n",
    "        print(f\"Fetching NDVI data for chip {chip_idx}\")\n",
    "        ndvi = ndvi_from_topleft([top, left], epsg, chip_date,resolution=375)\n",
    "\n",
    "        if ndvi is not None:\n",
    "            np.save(output_dir.joinpath('ndvi.npy'), ndvi)\n",
    "            print(\"NDVI data completed\")\n",
    "        else:\n",
    "            print(\"No NDVI data available for this chip\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching NDVI data: {e}\")    \n",
    "    \n",
    "    \n",
    "    # save bbox to geojson\n",
    "    bounds_utm = rasterio.coords.BoundingBox(left=left, right=right, bottom=bottom, top=top)\n",
    "    gpd.GeoSeries([box(*bounds_utm)]).set_crs(epsg).to_file(output_dir.joinpath('bbox.geojson'))\n",
    "    \n",
    "    # # load fires\n",
    "    # todays_fires = fires_from_topleft([top, left], epsg, chip_date, fires=fires)\n",
    "    # np.save(output_dir.joinpath(f'todays_fires.npy'), todays_fires.bool)\n",
    "    # np.save(output_dir.joinpath(f'todays_frp.npy'), todays_fires.frp)\n",
    "    # print(\"today fire completed\")\n",
    "    \n",
    "    \n",
    "#     # load fires\n",
    "#     todays_day_fires = fires_from_topleft([top, left], epsg, chip_date, fires=fires[fire[\"daynight\"] == \"D\"')\n",
    "#     np.save(output_dir.joinpath(f'todays_fires.npy'), todays_fires.bool)\n",
    "#     np.save(output_dir.joinpath(f'todays_frp.npy'), todays_fires.frp)\n",
    "#     print(\"today fire completed\") \n",
    "    \n",
    "    \n",
    "#     # load tomorrows fires if training\n",
    "    \n",
    "#     if training:\n",
    "#         tomorrows_date = (datetime.strptime(chip_date, '%Y-%m-%d') + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "#         tomorrows_fires = fires_from_topleft([top, left], epsg, tomorrows_date, fires=fires)\n",
    "#         np.save(output_dir.joinpath(f'tomorrows_fires.npy'), tomorrows_fires.bool)\n",
    "#         np.save(output_dir.joinpath(f'tomorrows_frp.npy'), tomorrows_fires.frp)\n",
    "    \n",
    "    # Load today's day fires\n",
    "    todays_day_fires = fires_from_topleft([top, left], epsg, chip_date, fires=fires[fires[\"daynight\"] == \"D\"])\n",
    "    np.save(output_dir.joinpath(f'todays_day_fires.npy'), todays_day_fires.bool)\n",
    "    np.save(output_dir.joinpath(f'todays_day_frp.npy'), todays_day_fires.frp)\n",
    "    print(\"Today's day fire data completed\")\n",
    "\n",
    "    # Load today's night fires\n",
    "    todays_night_fires = fires_from_topleft([top, left], epsg, chip_date, fires=fires[fires[\"daynight\"] == \"N\"])\n",
    "    np.save(output_dir.joinpath(f'todays_night_fires.npy'), todays_night_fires.bool)\n",
    "    np.save(output_dir.joinpath(f'todays_night_frp.npy'), todays_night_fires.frp)\n",
    "    print(\"Today's night fire data completed\")\n",
    "\n",
    "    # Load tomorrow's fires if training\n",
    "    if training:\n",
    "        tomorrows_date = (datetime.strptime(chip_date, '%Y-%m-%d') + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "\n",
    "        # Load tomorrow's day fires\n",
    "        tomorrows_day_fires = fires_from_topleft([top, left], epsg, tomorrows_date, fires=fires[fires[\"daynight\"] == \"D\"])\n",
    "        np.save(output_dir.joinpath(f'tomorrows_day_fires.npy'), tomorrows_day_fires.bool)\n",
    "        np.save(output_dir.joinpath(f'tomorrows_day_frp.npy'), tomorrows_day_fires.frp)\n",
    "        print(\"Tomorrow's day fire data completed\")\n",
    "\n",
    "        # Load tomorrow's night fires\n",
    "        tomorrows_night_fires = fires_from_topleft([top, left], epsg, tomorrows_date, fires=fires[fires[\"daynight\"] == \"N\"])\n",
    "        np.save(output_dir.joinpath(f'tomorrows_night_fires.npy'), tomorrows_night_fires.bool)\n",
    "        np.save(output_dir.joinpath(f'tomorrows_night_frp.npy'), tomorrows_night_fires.frp)\n",
    "        print(\"Tomorrow's night fire data completed\")\n",
    "\n",
    "    # dem = elevation_from_topleft([top, left], epsg)\n",
    "    # np.save(output_dir.joinpath('elevation.npy'), dem)\n",
    "    # Load DEM\n",
    "    try:\n",
    "        print(f\"Fetching elevation data for top_left: {[top, left]}, EPSG: {epsg}\")\n",
    "        dem = elevation_from_topleft([top, left], epsg, resolution=30)\n",
    "        np.save(output_dir.joinpath('elevation.npy'), dem)\n",
    "        print(\"DEM data completed\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading DEM data: {e}\")\n",
    "      \n",
    "\n",
    "    \n",
    "#     # load landcover\n",
    "#     landcover = landcover_from_topleft([top, left], epsg)\n",
    "#     np.save(output_dir.joinpath('landcover.npy'), landcover)\n",
    "#     print(\"landcover completed\")\n",
    "\n",
    "    \n",
    "#     # load atmospheric\n",
    "#     atmos = atmospheric_from_topleft([top, left], epsg, chip_date, DEFAULT_PARAMS)\n",
    "#     for var in list(atmos.data_vars):\n",
    "#         data_arr = getattr(atmos, var).values[0]\n",
    "#         np.save(output_dir.joinpath(f'{var}.npy'), data_arr)\n",
    "# Load landcover\n",
    "    try:\n",
    "        landcover = landcover_from_topleft([top, left], epsg)\n",
    "        np.save(output_dir.joinpath('landcover.npy'), landcover)\n",
    "        print(\"Landcover data completed\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading landcover data: {e}\")\n",
    "\n",
    "    # Load atmospheric data\n",
    "    # try:\n",
    "    #     atmos = atmospheric_from_topleft([top, left], epsg, chip_date, DEFAULT_PARAMS)\n",
    "    #     for var in list(atmos.data_vars):\n",
    "    #         data_arr = getattr(atmos, var).values[0]\n",
    "    #         np.save(output_dir.joinpath(f'{var}.npy'), data_arr)\n",
    "    #     print(\"Atmospheric data completed\")\n",
    "    # except Exception as e:\n",
    "    #     print(f\"Error loading atmospheric data: {e}\")\n",
    "    # Load atmospheric data\n",
    "#     try:\n",
    "#         atmos = atmospheric_from_topleft([top, left], epsg, chip_date, DEFAULT_PARAMS, resolution=375)\n",
    "\n",
    "#         # Assuming atmos is a dictionary, process the data based on keys, not 'data_vars'\n",
    "#         for param, data in atmos.items():  # Loop through each key-value pair in the dictionary\n",
    "#             if data:  # Check if there is valid data for the parameter\n",
    "#                 # Save the data (assuming data is in the correct format for saving)\n",
    "#                 np.save(output_dir.joinpath(f'{param}.npy'), data)\n",
    "#                 print(f\"{param} data completed\")\n",
    "#             else:\n",
    "#                 print(f\"No data available for {param}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error loading atmospheric data: {e}\")\n",
    "\n",
    "# Load atmospheric data\n",
    "    try:\n",
    "        atmos = atmospheric_from_topleft([top, left], epsg, chip_date, DEFAULT_PARAMS, resolution=375)\n",
    "\n",
    "        # Assuming atmos is a dictionary, process the data based on keys\n",
    "        for param, data in atmos.items():  # Loop through each key-value pair in the dictionary\n",
    "            try:\n",
    "                # Save the data directly\n",
    "                np.save(output_dir.joinpath(f'{param}.npy'), data)\n",
    "                print(f\"{param} data completed\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing parameter {param}: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading atmospheric data: {e}\")\n",
    "\n",
    "\n",
    "    fs.upload(str(output_dir), x\n",
    "              f'{output_s3}/{chip_idx}/',\n",
    "             recursive=True)\n",
    "    shutil.rmtree(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8eec0997-79b8-4ef4-922c-b3ad7f6a5720",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:fiona._env:GDAL_DATA found in environment.\n",
      "DEBUG:fiona._env:PROJ_LIB found in environment.\n",
      "DEBUG:fiona.ogrext:Removing GeoJSON file\n",
      "DEBUG:fiona._env:GDAL_DATA found in environment.\n",
      "DEBUG:fiona._env:PROJ_LIB found in environment.\n",
      "DEBUG:fiona._env:GDAL_DATA found in environment.\n",
      "DEBUG:fiona._env:PROJ_LIB found in environment.\n",
      "DEBUG:fiona.ogrext:Created layer OgrGeoJSON\n",
      "DEBUG:fiona.ogrext:Writing started\n",
      "DEBUG:fiona._env:GDAL_DATA found in environment.\n",
      "DEBUG:fiona._env:PROJ_LIB found in environment.\n",
      "DEBUG:fiona.ogrext:Transaction supported: 0\n",
      "DEBUG:fiona.ogrext:Flushed data source cache\n",
      "DEBUG:fiona.collection:Flushed buffer\n",
      "DEBUG:fiona.collection:Stopped session\n",
      "DEBUG:rasterio.env:Entering env context: <rasterio.env.Env object at 0x7f997e7b33a0>\n",
      "ERROR 4: `/vsis3/copernicus-dem-90m/Copernicus_DSM_COG_30_N35_00_W102_00_DEM/Copernicus_DSM_COG_30_N35_00_W102_00_DEM.tif' does not exist in the file system, and is not recognized as a supported dataset name.\n",
      "Warning 1: Can't open /vsis3/copernicus-dem-90m/Copernicus_DSM_COG_30_N35_00_W102_00_DEM/Copernicus_DSM_COG_30_N35_00_W102_00_DEM.tif. Skipping it\n",
      "DEBUG:rasterio.env:Starting outermost env\n",
      "DEBUG:rasterio.env:No GDAL environment exists\n",
      "DEBUG:rasterio.env:New GDAL environment <rasterio._env.GDALEnv object at 0x7f997e7b33d0> created\n",
      "DEBUG:rasterio._env:GDAL_DATA found in environment.\n",
      "DEBUG:rasterio._env:PROJ_LIB found in environment.\n",
      "DEBUG:rasterio._env:Started GDALEnv: self=<rasterio._env.GDALEnv object at 0x7f997e7b33d0>.\n",
      "DEBUG:rasterio.env:Entered env context: <rasterio.env.Env object at 0x7f997e7b33a0>\n",
      "DEBUG:rasterio._base:Sharing flag: 0\n",
      "DEBUG:rasterio.env:Exiting env context: <rasterio.env.Env object at 0x7f997e7b33a0>\n",
      "DEBUG:rasterio.env:Cleared existing <rasterio._env.GDALEnv object at 0x7f997e7b33d0> options\n",
      "DEBUG:rasterio._env:Stopped GDALEnv <rasterio._env.GDALEnv object at 0x7f997e7b33d0>.\n",
      "DEBUG:rasterio.env:Exiting outermost env\n",
      "DEBUG:rasterio.env:Exited env context: <rasterio.env.Env object at 0x7f997e7b33a0>\n",
      "DEBUG:fiona._env:GDAL_DATA found in environment.\n",
      "DEBUG:fiona._env:PROJ_LIB found in environment.\n",
      "DEBUG:fiona.ogrext:Removing GeoJSON file\n",
      "DEBUG:fiona._env:GDAL_DATA found in environment.\n",
      "DEBUG:fiona._env:PROJ_LIB found in environment.\n",
      "DEBUG:fiona._env:GDAL_DATA found in environment.\n",
      "DEBUG:fiona._env:PROJ_LIB found in environment.\n",
      "DEBUG:fiona.ogrext:Created layer OgrGeoJSON\n",
      "DEBUG:fiona.ogrext:Writing started\n",
      "DEBUG:fiona._env:GDAL_DATA found in environment.\n",
      "DEBUG:fiona._env:PROJ_LIB found in environment.\n",
      "DEBUG:fiona.ogrext:Transaction supported: 0\n",
      "DEBUG:fiona.ogrext:Flushed data source cache\n",
      "DEBUG:fiona.collection:Flushed buffer\n",
      "DEBUG:fiona.collection:Stopped session\n",
      "DEBUG:rasterio.env:Entering env context: <rasterio.env.Env object at 0x7f997e7b33d0>\n",
      "ERROR 4: `/vsis3/copernicus-dem-90m/Copernicus_DSM_COG_30_N35_00_W103_00_DEM/Copernicus_DSM_COG_30_N35_00_W103_00_DEM.tif' does not exist in the file system, and is not recognized as a supported dataset name.\n",
      "Warning 1: Can't open /vsis3/copernicus-dem-90m/Copernicus_DSM_COG_30_N35_00_W103_00_DEM/Copernicus_DSM_COG_30_N35_00_W103_00_DEM.tif. Skipping it\n",
      "DEBUG:rasterio.env:Starting outermost env\n",
      "DEBUG:rasterio.env:No GDAL environment exists\n",
      "DEBUG:rasterio.env:New GDAL environment <rasterio._env.GDALEnv object at 0x7f997e7b33a0> created\n",
      "DEBUG:rasterio._env:GDAL_DATA found in environment.\n",
      "DEBUG:rasterio._env:PROJ_LIB found in environment.\n",
      "DEBUG:rasterio._env:Started GDALEnv: self=<rasterio._env.GDALEnv object at 0x7f997e7b33a0>.\n",
      "DEBUG:rasterio.env:Entered env context: <rasterio.env.Env object at 0x7f997e7b33d0>\n",
      "DEBUG:rasterio._base:Sharing flag: 0\n",
      "DEBUG:rasterio.env:Exiting env context: <rasterio.env.Env object at 0x7f997e7b33d0>\n",
      "DEBUG:rasterio.env:Cleared existing <rasterio._env.GDALEnv object at 0x7f997e7b33a0> options\n",
      "DEBUG:rasterio._env:Stopped GDALEnv <rasterio._env.GDALEnv object at 0x7f997e7b33a0>.\n",
      "DEBUG:rasterio.env:Exiting outermost env\n",
      "DEBUG:rasterio.env:Exited env context: <rasterio.env.Env object at 0x7f997e7b33d0>\n",
      "DEBUG:fiona._env:GDAL_DATA found in environment.\n",
      "DEBUG:fiona._env:PROJ_LIB found in environment.\n",
      "DEBUG:fiona.ogrext:Removing GeoJSON file\n",
      "DEBUG:fiona._env:GDAL_DATA found in environment.\n",
      "DEBUG:fiona._env:PROJ_LIB found in environment.\n",
      "DEBUG:fiona._env:GDAL_DATA found in environment.\n",
      "DEBUG:fiona._env:PROJ_LIB found in environment.\n",
      "DEBUG:fiona.ogrext:Created layer OgrGeoJSON\n",
      "DEBUG:fiona.ogrext:Writing started\n",
      "DEBUG:fiona._env:GDAL_DATA found in environment.\n",
      "DEBUG:fiona._env:PROJ_LIB found in environment.\n",
      "DEBUG:fiona.ogrext:Transaction supported: 0\n",
      "DEBUG:fiona.ogrext:Flushed data source cache\n",
      "DEBUG:fiona.collection:Flushed buffer\n",
      "DEBUG:fiona.collection:Stopped session\n",
      "DEBUG:rasterio.env:Entering env context: <rasterio.env.Env object at 0x7f9963240f70>\n",
      "ERROR 4: `/vsis3/copernicus-dem-90m/Copernicus_DSM_COG_30_N36_00_W102_00_DEM/Copernicus_DSM_COG_30_N36_00_W102_00_DEM.tif' does not exist in the file system, and is not recognized as a supported dataset name.\n",
      "Warning 1: Can't open /vsis3/copernicus-dem-90m/Copernicus_DSM_COG_30_N36_00_W102_00_DEM/Copernicus_DSM_COG_30_N36_00_W102_00_DEM.tif. Skipping it\n",
      "DEBUG:rasterio.env:Starting outermost env\n",
      "DEBUG:rasterio.env:No GDAL environment exists\n",
      "DEBUG:rasterio.env:New GDAL environment <rasterio._env.GDALEnv object at 0x7f99626a7cd0> created\n",
      "DEBUG:rasterio._env:GDAL_DATA found in environment.\n",
      "DEBUG:rasterio._env:PROJ_LIB found in environment.\n",
      "DEBUG:rasterio._env:Started GDALEnv: self=<rasterio._env.GDALEnv object at 0x7f99626a7cd0>.\n",
      "DEBUG:rasterio.env:Entered env context: <rasterio.env.Env object at 0x7f9963240f70>\n",
      "DEBUG:rasterio._base:Sharing flag: 0\n",
      "DEBUG:rasterio.env:Exiting env context: <rasterio.env.Env object at 0x7f9963240f70>\n",
      "DEBUG:rasterio.env:Cleared existing <rasterio._env.GDALEnv object at 0x7f99626a7cd0> options\n",
      "DEBUG:rasterio._env:Stopped GDALEnv <rasterio._env.GDALEnv object at 0x7f99626a7cd0>.\n",
      "DEBUG:rasterio.env:Exiting outermost env\n",
      "DEBUG:rasterio.env:Exited env context: <rasterio.env.Env object at 0x7f9963240f70>\n",
      "DEBUG:fiona._env:GDAL_DATA found in environment.\n",
      "DEBUG:fiona._env:PROJ_LIB found in environment.\n",
      "DEBUG:fiona.ogrext:Removing GeoJSON file\n",
      "DEBUG:fiona._env:GDAL_DATA found in environment.\n",
      "DEBUG:fiona._env:PROJ_LIB found in environment.\n",
      "DEBUG:fiona._env:GDAL_DATA found in environment.\n",
      "DEBUG:fiona._env:PROJ_LIB found in environment.\n",
      "DEBUG:fiona.ogrext:Created layer OgrGeoJSON\n",
      "DEBUG:fiona.ogrext:Writing started\n",
      "DEBUG:fiona._env:GDAL_DATA found in environment.\n",
      "DEBUG:fiona._env:PROJ_LIB found in environment.\n",
      "DEBUG:fiona.ogrext:Transaction supported: 0\n",
      "DEBUG:fiona.ogrext:Flushed data source cache\n",
      "DEBUG:fiona.collection:Flushed buffer\n",
      "DEBUG:fiona.collection:Stopped session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing\n",
      "Chip read completed\n",
      "Processing chip: 0\n",
      "Fetching elevation data for top_left: [3954750.0, 274125.0], EPSG: 32614\n",
      "Error loading DEM data: 486a8d99-e439-41f5-8377-c6176f744931_temp.vrt: No such file or directory\n",
      "Data saved locally at sagemaker-studiolab-notebooks/SatelliteVu-AWS-Disaster-Response-Hackathon/dataset_preparation/src/0\n",
      "Start processing\n",
      "Chip read completed\n",
      "Processing chip: 1\n",
      "Fetching elevation data for top_left: [3965250.0, 738000.0], EPSG: 32613\n",
      "Error loading DEM data: 641cf48d-d6a5-45a2-9920-a2df8767d754_temp.vrt: No such file or directory\n",
      "Data saved locally at sagemaker-studiolab-notebooks/SatelliteVu-AWS-Disaster-Response-Hackathon/dataset_preparation/src/1\n",
      "Start processing\n",
      "Chip read completed\n",
      "Processing chip: 2\n",
      "Fetching elevation data for top_left: [4079625.0, 247500.0], EPSG: 32614\n",
      "Error loading DEM data: 397977a1-ab97-478e-a6a3-bea20bac1773_temp.vrt: No such file or directory\n",
      "Data saved locally at sagemaker-studiolab-notebooks/SatelliteVu-AWS-Disaster-Response-Hackathon/dataset_preparation/src/2\n",
      "Start processing\n",
      "Chip read completed\n",
      "Processing chip: 3\n",
      "Fetching elevation data for top_left: [4091625.0, 546750.0], EPSG: 32614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:rasterio.env:Entering env context: <rasterio.env.Env object at 0x7f99626a79a0>\n",
      "ERROR 4: `/vsis3/copernicus-dem-90m/Copernicus_DSM_COG_30_N36_00_W099_00_DEM/Copernicus_DSM_COG_30_N36_00_W099_00_DEM.tif' does not exist in the file system, and is not recognized as a supported dataset name.\n",
      "Warning 1: Can't open /vsis3/copernicus-dem-90m/Copernicus_DSM_COG_30_N36_00_W099_00_DEM/Copernicus_DSM_COG_30_N36_00_W099_00_DEM.tif. Skipping it\n",
      "DEBUG:rasterio.env:Starting outermost env\n",
      "DEBUG:rasterio.env:No GDAL environment exists\n",
      "DEBUG:rasterio.env:New GDAL environment <rasterio._env.GDALEnv object at 0x7f9963240f70> created\n",
      "DEBUG:rasterio._env:GDAL_DATA found in environment.\n",
      "DEBUG:rasterio._env:PROJ_LIB found in environment.\n",
      "DEBUG:rasterio._env:Started GDALEnv: self=<rasterio._env.GDALEnv object at 0x7f9963240f70>.\n",
      "DEBUG:rasterio.env:Entered env context: <rasterio.env.Env object at 0x7f99626a79a0>\n",
      "DEBUG:rasterio._base:Sharing flag: 0\n",
      "DEBUG:rasterio.env:Exiting env context: <rasterio.env.Env object at 0x7f99626a79a0>\n",
      "DEBUG:rasterio.env:Cleared existing <rasterio._env.GDALEnv object at 0x7f9963240f70> options\n",
      "DEBUG:rasterio._env:Stopped GDALEnv <rasterio._env.GDALEnv object at 0x7f9963240f70>.\n",
      "DEBUG:rasterio.env:Exiting outermost env\n",
      "DEBUG:rasterio.env:Exited env context: <rasterio.env.Env object at 0x7f99626a79a0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading DEM data: 5d97580b-a05c-4ed0-be0b-59fbed502115_temp.vrt: No such file or directory\n",
      "Data saved locally at sagemaker-studiolab-notebooks/SatelliteVu-AWS-Disaster-Response-Hackathon/dataset_preparation/src/3\n"
     ]
    }
   ],
   "source": [
    "def process_chip_to_local(chip, output_fp, fires, training=True):\n",
    "    \"\"\"\n",
    "    Given a chip's metadata, load all of the training data and write numpy files locally.\n",
    "\n",
    "    :param chip: records.csv chip to process data for\n",
    "    :param output_fp: local directory to write data to\n",
    "    :param fires: gpd.GeoDataFrame or path to vector file containing fire point data\n",
    "    :param training: bool, if true, then will load/write next day's fires\n",
    "    \"\"\"\n",
    "    print(\"Start processing\")\n",
    "\n",
    "    chip_idx, left, bottom, top, right, epsg, chip_date = chip[\"idx\"], chip[\"left\"], chip[\"bottom\"], chip[\"top\"], chip[\"right\"], chip[\"epsg\"], chip[\"date\"]\n",
    "    print(\"Chip read completed\")\n",
    "\n",
    "    print(f'Processing chip: {chip_idx}')\n",
    "    \n",
    "    # Create output dir if it doesn't already exist\n",
    "    output_dir = Path(output_fp).joinpath(str(chip_idx))\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#     # Fetch NDVI data\n",
    "#     try:\n",
    "#         print(f\"Fetching NDVI data for chip {chip_idx}\")\n",
    "#         ndvi = ndvi_from_topleft([top, left], epsg, chip_date, resolution=375)\n",
    "\n",
    "#         if ndvi is not None:\n",
    "#             np.save(output_dir.joinpath('ndvi.npy'), ndvi)\n",
    "#             print(\"NDVI data completed\")\n",
    "#         else:\n",
    "#             print(\"No NDVI data available for this chip\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error fetching NDVI data: {e}\")\n",
    "\n",
    "    # Save bounding box to GeoJSON\n",
    "    bounds_utm = rasterio.coords.BoundingBox(left=left, right=right, bottom=bottom, top=top)\n",
    "    gpd.GeoSeries([box(*bounds_utm)]).set_crs(epsg).to_file(output_dir.joinpath('bbox.geojson'))\n",
    "\n",
    "    # Load today's day fires\n",
    "    # try:\n",
    "    #     todays_day_fires = fires_from_topleft([top, left], epsg, chip_date, fires=fires[fires[\"daynight\"] == \"D\"])\n",
    "    #     np.save(output_dir.joinpath(f'todays_day_fires.npy'), todays_day_fires.bool)\n",
    "    #     np.save(output_dir.joinpath(f'todays_day_frp.npy'), todays_day_fires.frp)\n",
    "    #     print(\"Today's day fire data completed\")\n",
    "    # except Exception as e:\n",
    "    #     print(f\"Error loading today's day fires: {e}\")\n",
    "\n",
    "    # Load today's night fires\n",
    "#     try:\n",
    "#         todays_night_fires = fires_from_topleft([top, left], epsg, chip_date, fires=fires[fires[\"daynight\"] == \"N\"])\n",
    "#         np.save(output_dir.joinpath(f'todays_night_fires.npy'), todays_night_fires.bool)\n",
    "#         np.save(output_dir.joinpath(f'todays_night_frp.npy'), todays_night_fires.frp)\n",
    "#         print(\"Today's night fire data completed\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error loading today's night fires: {e}\")\n",
    "\n",
    "#     # Load tomorrow's fires if training\n",
    "#     if training:\n",
    "#         try:\n",
    "#             tomorrows_date = (datetime.strptime(chip_date, '%Y-%m-%d') + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "\n",
    "#             # Load tomorrow's day fires\n",
    "#             tomorrows_day_fires = fires_from_topleft([top, left], epsg, tomorrows_date, fires=fires[fires[\"daynight\"] == \"D\"])\n",
    "#             np.save(output_dir.joinpath(f'tomorrows_day_fires.npy'), tomorrows_day_fires.bool)\n",
    "#             np.save(output_dir.joinpath(f'tomorrows_day_frp.npy'), tomorrows_day_fires.frp)\n",
    "#             print(\"Tomorrow's day fire data completed\")\n",
    "\n",
    "#             # Load tomorrow's night fires\n",
    "#             tomorrows_night_fires = fires_from_topleft([top, left], epsg, tomorrows_date, fires=fires[fires[\"daynight\"] == \"N\"])\n",
    "#             np.save(output_dir.joinpath(f'tomorrows_night_fires.npy'), tomorrows_night_fires.bool)\n",
    "#             np.save(output_dir.joinpath(f'tomorrows_night_frp.npy'), tomorrows_night_fires.frp)\n",
    "#             print(\"Tomorrow's night fire data completed\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error loading tomorrow's fires: {e}\")\n",
    "\n",
    "    #Fetch DEM data\n",
    "    try:\n",
    "        print(f\"Fetching elevation data for top_left: {[top, left]}, EPSG: {epsg}\")\n",
    "        dem = elevation_from_topleft([top, left], epsg, resolution=30)\n",
    "        np.save(output_dir.joinpath('elevation.npy'), dem)\n",
    "        print(\"DEM data completed\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading DEM data: {e}\")\n",
    "\n",
    "    # Fetch landcover data\n",
    "#     try:\n",
    "#         #landcover = landcover_from_topleft([top, left], epsg, chip_date,resolution = 375) \n",
    "#         landcover = landcover_from_topleft([top, left], epsg)\n",
    "\n",
    "#         np.save(output_dir.joinpath('landcover.npy'), landcover)\n",
    "#         print(\"Landcover data completed\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error loading landcover data: {e}\")\n",
    "\n",
    "    # Fetch atmospheric data\n",
    "    # try:\n",
    "    #     atmos = atmospheric_from_topleft([top, left], epsg, chip_date, DEFAULT_PARAMS, resolution=375)\n",
    "    #     for param, data in atmos.items():  # Loop through each key-value pair in the dictionary\n",
    "    #         try:\n",
    "    #             np.save(output_dir.joinpath(f'{param}.npy'), data)\n",
    "    #             print(f\"{param} data completed\")\n",
    "    #         except Exception as e:\n",
    "    #             print(f\"Error processing parameter {param}: {e}\")\n",
    "    # except Exception as e:\n",
    "    #     print(f\"Error loading atmospheric data: {e}\")\n",
    "\n",
    "    print(f\"Data saved locally at {output_dir}\")\n",
    "output_fp = \"sagemaker-studiolab-notebooks/SatelliteVu-AWS-Disaster-Response-Hackathon/dataset_preparation/src/\"  # Path to save locally\n",
    "chips = list(manifest.T.to_dict().values())\n",
    "for chip in chips:\n",
    "    process_chip_to_local(chip,  output_fp,  gdf_fires,  training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db93b4a-4fd1-4729-8fdc-f6b8c2e1e4d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chips = list(manifest.T.to_dict().values())\n",
    "print(f'Chips total = {len(chips)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b3e67d-5047-491c-9da0-8e8f74fc8df0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# query s3 to see which chips already processed and remove from list\n",
    "processed_chips = fs.ls(output_s3)\n",
    "processed_chips "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72836cff-3772-403a-b0dc-fdcf9e9a1eb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processed_ids = [int(x.split('/')[-1]) for x in processed_chips if x.split('/')[-1].isdigit()]\n",
    "processed_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985331a2-8f94-4a7e-8e51-d6c39cb98638",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# query s3 to see which chips already processed and remove from list\n",
    "processed_chips = fs.ls(output_s3)\n",
    "processed_ids = [int(x.split('/')[-1]) for x in processed_chips if x.split('/')[-1].isdigit()]\n",
    "print(f'Processed = {len(processed_ids)}')\n",
    "to_process = [x for x in chips if x['idx'] not in processed_ids]\n",
    "print(f'To process = {len(to_process)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12349f3-9acd-4ac3-82b2-6ef98e531d18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install fiona==1.9.6 --force-reinstall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629dc0e2-8b11-45df-a4d6-320b6dc28b3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import math\n",
    "os.environ['AWS_NO_SIGN_REQUEST'] = 'True'\n",
    "print(\"start\")\n",
    "\n",
    "#cog_footprints = gpd.GeoDataFrame.from_file('s3://copernicus-dem-90m/tileList.txt')\n",
    "\n",
    "# with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
    "#     future_work = [\n",
    "#         executor.submit(process_chip, chip, fs, output_fp, output_s3, gdf_fires, cog_footprints, training=False) for chip in to_process\n",
    "#     ]\n",
    "with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
    "    future_work = [\n",
    "        executor.submit(process_chip, chip, fs, output_fp, output_s3, gdf_fires,  training=True) for chip in to_process\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22315f66-5023-4601-9301-dcfac0ae2c38",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Explore some of the processed chips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915d6190-109c-4c50-82e8-ff1b7a74d14d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for chip in [x for x in fs.ls(output_s3) if x.split('/')[-1].isdigit()]:\n",
    "    print(chip.split('/')[-1])\n",
    "    \n",
    "    try:\n",
    "        tf = np.load(fs.open(chip + '/todays_fires.npy'))\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "        \n",
    "#     fig, (ax1, ax3, ax4, ax5, ax6) = plt.subplots(1, 5, figsize=(20,20))\n",
    "\n",
    "#     im = ax1.imshow(tf)\n",
    "#     ax1.title.set_text('todays_fires')\n",
    "    \n",
    "#     lc = np.load(fs.open(chip + '/landcover.npy'))\n",
    "#     im = ax3.imshow(lc)\n",
    "#     ax3.title.set_text('land cover')\n",
    "\n",
    "#     el = np.load(fs.open(chip + '/elevation.npy'))\n",
    "#     im = ax4.imshow(el)\n",
    "#     ax4.title.set_text('elevation')\n",
    "    \n",
    "#     nd = np.load(fs.open(chip + '/ndvi.npy'))\n",
    "#     im = ax5.imshow(nd)\n",
    "#     ax5.title.set_text('ndvi')\n",
    "    \n",
    "#     sa = np.load(fs.open(chip + '/surface_air_pressure.npy'))\n",
    "#     im = ax6.imshow(sa)\n",
    "#     ax6.title.set_text('surface_air_pressure')\n",
    "\n",
    "    fig, (ax1, ax3, ax4) = plt.subplots(1, 3, figsize=(20,20))\n",
    "\n",
    "    im = ax1.imshow(tf)\n",
    "    ax1.title.set_text('todays_fires')\n",
    "    \n",
    "    lc = np.load(fs.open(chip + '/landcover.npy'))\n",
    "    im = ax3.imshow(lc)\n",
    "    ax3.title.set_text('land cover')\n",
    "\n",
    "    el = np.load(fs.open(chip + '/elevation.npy'))\n",
    "    im = ax4.imshow(el)\n",
    "    ax4.title.set_text('elevation')\n",
    "    \n",
    "#     nd = np.load(fs.open(chip + '/ndvi.npy'))\n",
    "#     im = ax5.imshow(nd)\n",
    "#     ax5.title.set_text('ndvi')\n",
    "    \n",
    "#     sa = np.load(fs.open(chip + '/surface_air_pressure.npy'))\n",
    "#     im = ax6.imshow(sa)\n",
    "#     ax6.title.set_text('surface_air_pressure')\n",
    "\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b877eb-008c-49d0-b115-ff1c1a5377f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for chip in [x for x in fs.ls(output_s3) if x.split('/')[-1].isdigit()]:\n",
    "    print(f\"Chip ID: {chip.split('/')[-1]}\")\n",
    "    \n",
    "    try:\n",
    "        # Load fire and additional data\n",
    "        day_fire = np.load(fs.open(chip + '/todays_day_fires.npy'))\n",
    "        night_fire = np.load(fs.open(chip + '/todays_night_fires.npy'))\n",
    "        tmr_day_fire = np.load(fs.open(chip + '/tomorrows_day_fires.npy'))\n",
    "        tmr_night_fire = np.load(fs.open(chip + '/tomorrows_night_fires.npy'))\n",
    "        landcover = np.load(fs.open(chip + '/landcover.npy'))\n",
    "        elevation = np.load(fs.open(chip + '/elevation.npy'))\n",
    "        temperature = np.load(fs.open(chip + '/wind_v.npy'),allow_pickle=True)\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Missing file for chip {chip.split('/')[-1]}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(24, 12))\n",
    "\n",
    "    # Plot today's fires (day and night)\n",
    "    axs[0, 0].imshow(day_fire)\n",
    "    axs[0, 0].set_title(\"Today's Day Fire\")\n",
    "    axs[0, 1].imshow(night_fire)\n",
    "    axs[0, 1].set_title(\"Today's Night Fire\")\n",
    "\n",
    "    # Plot tomorrow's fires (day and night)\n",
    "    axs[0, 2].imshow(tmr_day_fire)\n",
    "    axs[0, 2].set_title(\"Tomorrow's Day Fire\")\n",
    "    axs[0, 3].imshow(tmr_night_fire)\n",
    "    axs[0, 3].set_title(\"Tomorrow's Night Fire\")\n",
    "\n",
    "    # Plot additional bands\n",
    "    axs[1, 1].imshow(landcover)\n",
    "    axs[1, 1].set_title(\"Landcover\")\n",
    "    axs[1, 2].imshow(elevation)\n",
    "    axs[1, 2].set_title(\"Elevation\")\n",
    "    axs[1, 0].imshow(temperature,cmap='viridis')\n",
    "    axs[1, 0].set_title(\"wind_v\")\n",
    "\n",
    "    # Adjust layout\n",
    "    for ax in axs.flat:\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097781ea-099e-444e-9e05-15f0da525c08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "for chip in [x for x in fs.ls(output_s3) if x.split('/')[-1].isdigit()]:\n",
    "    print(f\"Chip ID: {chip.split('/')[-1]}\")\n",
    "    \n",
    "    try:\n",
    "        # Load fire and additional data\n",
    "        day_fire = np.load(fs.open(chip + '/todays_day_fires.npy'))\n",
    "        night_fire = np.load(fs.open(chip + '/todays_night_fires.npy'))\n",
    "        tmr_day_fire = np.load(fs.open(chip + '/tomorrows_day_fires.npy'))\n",
    "        tmr_night_fire = np.load(fs.open(chip + '/tomorrows_night_fires.npy'))\n",
    "        landcover = np.load(fs.open(chip + '/landcover.npy'))\n",
    "        elevation = np.load(fs.open(chip + '/elevation.npy'))\n",
    "        temperature = np.load(fs.open(chip + '/temperature.npy'),allow_pickle=True)\n",
    "                # Inspect temperature data\n",
    "        print(f\"Temperature dtype: {temperature.dtype}\")\n",
    "        print(f\"Temperature shape: {temperature.shape}\")\n",
    "                # Ensure it's numeric and handle missing values\n",
    "        # If it's a dictionary, extract the actual data\n",
    "        if isinstance(temperature, dict):\n",
    "            print(f\"Temperature dictionary keys: {temperature.keys()}\")\n",
    "            temperature = temperature.get('desired_key')  # Replace 'desired_key' with the correct key for temperature data\n",
    "        \n",
    "        # Ensure it's numeric and handle missing values\n",
    "        if isinstance(temperature, np.ndarray):\n",
    "            temperature = np.nan_to_num(temperature, nan=0.0)  # Replace NaNs with 0\n",
    "            \n",
    "        specific_humidity = np.load(fs.open(chip + '/specific_humidity.npy'),allow_pickle=True)\n",
    "        pressure = np.load(fs.open(chip + '/pressure.npy'),allow_pickle=True)\n",
    "        wind_u = np.load(fs.open(chip + '/wind_u.npy'),allow_pickle=True)\n",
    "        wind_v = np.load(fs.open(chip + '/wind_v.npy'),allow_pickle=True)\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Missing file for chip {chip.split('/')[-1]}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axs = plt.subplots(3, 4, figsize=(24, 18))\n",
    "\n",
    "    # Plot today's fires (day and night)\n",
    "    axs[0, 0].imshow(day_fire)\n",
    "    axs[0, 0].set_title(\"Today's Day Fire\")\n",
    "    axs[0, 1].imshow(night_fire)\n",
    "    axs[0, 1].set_title(\"Today's Night Fire\")\n",
    "\n",
    "    # Plot tomorrow's fires (day and night)\n",
    "    axs[0, 2].imshow(tmr_day_fire)\n",
    "    axs[0, 2].set_title(\"Tomorrow's Day Fire\")\n",
    "    axs[0, 3].imshow(tmr_night_fire)\n",
    "    axs[0, 3].set_title(\"Tomorrow's Night Fire\")\n",
    "\n",
    "    # Plot additional bands\n",
    "    axs[1, 0].imshow(landcover)\n",
    "    axs[1, 0].set_title(\"Landcover\")\n",
    "    axs[1, 1].imshow(elevation)\n",
    "    axs[1, 1].set_title(\"Elevation\")\n",
    "    axs[1, 2].imshow(temperature)\n",
    "    axs[1, 2].set_title(\"Temperature\")\n",
    "    axs[1, 3].imshow(specific_humidity)\n",
    "    axs[1, 3].set_title(\"Specific Humidity\")\n",
    "\n",
    "    # Plot atmospheric bands\n",
    "    axs[2, 0].imshow(pressure)\n",
    "    axs[2, 0].set_title(\"Pressure\")\n",
    "    axs[2, 1].imshow(wind_u)\n",
    "    axs[2, 1].set_title(\"Wind U Component\")\n",
    "    axs[2, 2].imshow(wind_v)\n",
    "    axs[2, 2].set_title(\"Wind V Component\")\n",
    "\n",
    "    # Adjust layout\n",
    "    for ax in axs.flat:\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48e04b2-4a7c-4b6e-a076-e989350e0b0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "\n",
    "# Initialize the Earth Engine API\n",
    "ee.Initialize()\n",
    "\n",
    "# Test by printing a simple dataset description\n",
    "print(ee.ImageCollection('ECMWF/ERA5_LAND/HOURLY').first().getInfo())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24ee64a-c287-4a73-9b12-31b7849d170b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install earthengine-api --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435f8509-221e-48a1-89e8-073e39227501",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "\n",
    "# Initialize the Earth Engine API with your project ID\n",
    "ee.Initialize(project='cultivated-card-441523-g2')\n",
    "\n",
    "# Test the connection\n",
    "print(ee.ImageCollection('ECMWF/ERA5_LAND/HOURLY').first().getInfo())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62905278-cdd1-4e9a-91ca-630685c8ed68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize the Earth Engine API\n",
    "ee.Initialize(project='cultivated-card-441523-g2')\n",
    "\n",
    "# Define your AOI (Area of Interest)\n",
    "# Example coordinates, replace with your own coordinates\n",
    "top_left = [37.7749, -122.4194]  # Latitude, Longitude\n",
    "aoi = ee.Geometry.Point([39, 74]).buffer(500)\n",
    "\n",
    "# Define parameters (e.g., 'temperature_2m')\n",
    "params = ['pr']\n",
    "\n",
    "# Function to fetch and plot atmospheric data\n",
    "def fetch_and_plot_atmospheric_data(start_date, end_date, aoi, params, resolution=500):\n",
    "    # Filter for the given date range and region\n",
    "    weather = ee.ImageCollection(\"IDAHO_EPSCOR/GRIDMET\") \\\n",
    "        .filterDate(start_date, end_date) \\\n",
    "        .filterBounds(aoi)\n",
    "\n",
    "    # Fetch each parameter, e.g., temperature\n",
    "    for param in params:\n",
    "        try:\n",
    "            param_data = weather.select(param).reproject(crs='EPSG:4326', scale=resolution)\n",
    "\n",
    "\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {param}: {e}\")\n",
    "\n",
    "# Call the function with your date range and AOI\n",
    "fetch_and_plot_atmospheric_data(\"2022-01-01\", \"2022-01-02\", aoi, params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec2f424-fa9a-483f-8977-4240425f9087",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fetch_and_plot_atmospheric_data(start_date, end_date, aoi, params, resolution=500):\n",
    "    # Filter for the given date range and region\n",
    "    weather = ee.ImageCollection(\"IDAHO_EPSCOR/GRIDMET\") \\\n",
    "        .filterDate(start_date, end_date) \\\n",
    "        .filterBounds(aoi)\n",
    "\n",
    "    for param in params:\n",
    "        try:\n",
    "            # Select the parameter and calculate mean\n",
    "            param_data = weather.select(param).mean().reproject(crs='EPSG:4326', scale=resolution)\n",
    "\n",
    "            # Aggregate data using reduceRegion\n",
    "            data = param_data.reduceRegion(\n",
    "                reducer=ee.Reducer.mean(),\n",
    "                geometry=aoi,\n",
    "                scale=resolution,\n",
    "                maxPixels=1e9\n",
    "            ).getInfo()\n",
    "\n",
    "            # Check if the parameter exists in the data\n",
    "            if param in data:\n",
    "                value = data[param]\n",
    "                print(f\"{param} mean value: {value}\")\n",
    "                \n",
    "                # Plot the mean value as a placeholder visualization\n",
    "                plt.bar([param], [value], color='blue')\n",
    "                plt.title(f\"{param} Mean Value\\n{start_date} to {end_date}\")\n",
    "                plt.ylabel(param)\n",
    "                plt.show()\n",
    "            else:\n",
    "                raise KeyError(f\"Parameter '{param}' not found in the data\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {param}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61982a4-6b8f-4b04-afed-ddcb86addb6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize Earth Engine\n",
    "ee.Initialize(project='cultivated-card-441523-g2')\n",
    "\n",
    "# Define AOI and parameters\n",
    "aoi = ee.Geometry.Point([-97.7431, 30.2672]).buffer(100000)  # Example AOI in Texas\n",
    "params = ['specific_humidity', 'temperature','wind_u']  # Specific humidity\n",
    "\n",
    "def fetch_and_plot_heatmap(start_date, end_date, aoi, params, resolution=505):\n",
    "    weather = ee.ImageCollection(\"NASA/NLDAS/FORA0125_H002\") \\\n",
    "        .filterDate(start_date, end_date) \\\n",
    "        .filterBounds(aoi)\n",
    "\n",
    "    for param in params:\n",
    "        try:\n",
    "            # Select parameter and reproject to 500-meter resolution\n",
    "            param_data = weather.select(param).mean().reproject(\n",
    "                crs='EPSG:4326', scale=resolution\n",
    "            )\n",
    "\n",
    "            # Extract data as a NumPy array\n",
    "            data = param_data.sampleRectangle(region=aoi).getInfo()\n",
    "            if param not in data['properties']:\n",
    "                print(f\"No data found for parameter '{param}'.\")\n",
    "                continue\n",
    "\n",
    "            # Convert the raster data into a NumPy array\n",
    "            raster = np.array(data['properties'][param])\n",
    "\n",
    "            # Plot the heatmap\n",
    "            plt.imshow(raster, cmap='viridis')\n",
    "            plt.colorbar(label=param)\n",
    "            plt.title(f\"{param} from {start_date} to {end_date} at {resolution}m resolution\")\n",
    "            plt.show()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {param}: {e}\")\n",
    "\n",
    "# Call the function with 500-meter resolution\n",
    "fetch_and_plot_heatmap(\"2022-01-01\", \"2022-01-08\", aoi, params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b69ba9-6399-4f0b-abaa-aa5103c0c41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve dataset metadata\n",
    "import ee\n",
    "ee.Initialize(project='cultivated-card-441523-g2')  # Use your project ID\n",
    "metadata = ee.ImageCollection(\"NASA/VIIRS/002/VNP13A1\").first().getInfo()\n",
    "print(\"Dataset Metadata:\", metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609bc380-bb43-4763-bd64-1b6e7d339350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize Earth Engine\n",
    "ee.Initialize(project='cultivated-card-441523-g2')\n",
    "\n",
    "def fetch_and_plot_vegetation_heatmap(start_date, end_date, aoi, params, resolution=463):\n",
    "    # Load the vegetation dataset\n",
    "    vegetation = ee.ImageCollection('NASA/VIIRS/002/VNP13A1') \\\n",
    "        .filterDate(start_date, end_date) \\\n",
    "        .filterBounds(aoi)\n",
    "    \n",
    "    for param in params:\n",
    "        try:\n",
    "            # Select the vegetation index (e.g., NDVI)\n",
    "            param_data = vegetation.select(param).mean().reproject(\n",
    "                crs='EPSG:4326', scale=resolution\n",
    "            )\n",
    "            \n",
    "            # Extract data as a NumPy array\n",
    "            data = param_data.sampleRectangle(region=aoi).getInfo()\n",
    "            if param not in data['properties']:\n",
    "                print(f\"No data found for parameter '{param}'.\")\n",
    "                continue\n",
    "\n",
    "            # Apply scaling factor (if required)\n",
    "            raster = np.array(data['properties'][param]) * 0.0001  # Adjust scale as needed\n",
    "\n",
    "            # Plot the heatmap\n",
    "            plt.imshow(raster, cmap='viridis')\n",
    "            plt.colorbar(label=f\"{param} (scaled)\")\n",
    "            plt.title(f\"{param} from {start_date} to {end_date} at {resolution}m resolution\")\n",
    "            plt.show()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {param}: {e}\")\n",
    "\n",
    "# Example Call\n",
    "fetch_and_plot_vegetation_heatmap(\n",
    "    start_date=\"2022-01-01\",\n",
    "    end_date=\"2022-01-06\",\n",
    "    aoi = ee.Geometry.Point([-97.7431, 30.2672]).buffer(10000),  # Example AOI in Texas\n",
    "    params=['NDVI', 'EVI'],  # Example vegetation indices\n",
    "    resolution=463\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3343331c-0126-4175-b23a-03ea8f74d4a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import rasterio\n",
    "\n",
    "try:\n",
    "    with rasterio.open(\"/vsis3/esa-worldcover/v100/2020/map/ESA_WorldCover_10m_2020_v100_S27E030_Map.tif\") as src:\n",
    "        print(\"Bounds:\", src.bounds)\n",
    "        print(\"CRS:\", src.crs)\n",
    "        print(\"Metadata:\", src.meta)\n",
    "except Exception as e:\n",
    "    print(f\"Failed to read file: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2f4257-9884-4aaa-b22f-83c76b98fc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from rasterio.env import Env\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "with Env(aws_unsigned=True):\n",
    "    try:\n",
    "        with rasterio.open(\"/vsis3/esa-worldcover/v100/2020/ESA_WorldCover_10m_2020_v100_Map_AWS.vrt\") as src:\n",
    "            print(src.meta)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c9ae47-9983-4240-8426-6c46f2392b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-default:Python",
   "language": "python",
   "name": "conda-env-.conda-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
